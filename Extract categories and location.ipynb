{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import logging\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('venues_barcelona.csv', index_col = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to get overarching category\n",
    "import re\n",
    "def get_category(row):\n",
    "    if \"arts_entertainment\" in row['categories']:\n",
    "        category= \"arts_entertainment\"\n",
    "    elif \"food\" in row['categories']:\n",
    "        category= \"food\"\n",
    "    elif \"shops\" in row['categories']:\n",
    "        category= \"shops\" \n",
    "    elif \"travel\" in row['categories']:\n",
    "        category= \"travel\"    \n",
    "    elif \"nightlife\" in row['categories']:\n",
    "        category= \"nightlife\"\n",
    "    elif \"education\" in row['categories']:\n",
    "        category= \"education\"\n",
    "    elif \"parks_outdoors\" in row['categories']:\n",
    "        category= \"parks_outdoors\"               \n",
    "    elif \"building\" in row['categories']:\n",
    "        category= \"building\"        \n",
    "    else: \n",
    "        category = \"other\"\n",
    "    return category   \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to obtain detailed category\n",
    "def get_detailedcategory(row):\n",
    "    try:\n",
    "        start = row['categories'].index( \"name':\" ) + len(\"name':\")\n",
    "        end = row['categories'].index( \", 'pluralName\", start )\n",
    "        return row['categories'][start:end]\n",
    "    except ValueError:\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get latitude\n",
    "def get_lat(row):\n",
    "    try:\n",
    "        start = row['location'].index( \"'lat': \" ) + len(\"'lat': \")\n",
    "        end = row['location'].index( \", 'lng\", start )\n",
    "        return row['location'][start:end]\n",
    "    except ValueError:\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get longitude\n",
    "def get_lon(row):\n",
    "    try:\n",
    "        start = row['location'].index( \"'lng': \" ) + len(\"'lng': \")\n",
    "        end = row['location'].index( \", 'labeledLatLngs':\", start )\n",
    "        return row['location'][start:end]\n",
    "    except ValueError:\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new columns with categories and location\n",
    "df['categories']=df['categories'].astype(str)\n",
    "df['category']=df.apply(get_category, axis=1)\n",
    "df['category_detail'] = df.apply(get_detailedcategory, axis=1)\n",
    "df['lat']=df.apply(get_lat, axis=1)\n",
    "df['lon']=df.apply(get_lon, axis=1)\n",
    "df['latlon']=df['lat'] + \",\" + df['lon']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## to geocode postal code or address \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(\"root\")\n",
    "logger.setLevel(logging.DEBUG)\n",
    "# create console handler\n",
    "ch = logging.StreamHandler()\n",
    "ch.setLevel(logging.DEBUG)\n",
    "logger.addHandler(ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your Google API key here. \n",
    "# Even if using the free 2500 queries a day, its worth getting an API key since the rate limit is 50 / second.\n",
    "# With API_KEY = None, you will run into a 2 second delay every 10 requests or so.\n",
    "# With a \"Google Maps Geocoding API\" key from https://console.developers.google.com/apis/, \n",
    "# the daily limit will be 2500, but at a much faster rate.\n",
    "# Example: API_KEY = 'AIzaSyC9azed9tLdjpZNjg2_kVePWvMIBq154eA'\n",
    "API_KEY = 'AIzaSyCOi1jiEY1MXDlg9nJvL5sHmjqx-MNcDMo'\n",
    "# Backoff time sets how many minutes to wait between google pings when your API limit is hit\n",
    "BACKOFF_TIME = 30\n",
    "# Set your output file name here.\n",
    "output_filename = 'postalcode.csv'\n",
    "# Specify the column name in your input data that contains addresses here\n",
    "address_column_name = \"latlon\"\n",
    "# Return Full Google Results? If True, full JSON results from Google are included in output\n",
    "RETURN_FULL_RESULTS = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Form a list of addresses for geocoding:\n",
    "# Make a big list of all of the addresses to be processed.\n",
    "addresses = df[address_column_name].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_google_results(address, api_key=API_KEY, return_full_response=False):\n",
    "    \"\"\"\n",
    "    Get geocode results from Google Maps Geocoding API.\n",
    "    \n",
    "    Note, that in the case of multiple google geocode reuslts, this function returns details of the FIRST result.\n",
    "    \n",
    "    @param address: String address as accurate as possible. For Example \"18 Grafton Street, Dublin, Ireland\"\n",
    "    @param api_key: String API key if present from google. \n",
    "                    If supplied, requests will use your allowance from the Google API. If not, you\n",
    "                    will be limited to the free usage of 2500 requests per day.\n",
    "    @param return_full_response: Boolean to indicate if you'd like to return the full response from google. This\n",
    "                    is useful if you'd like additional location details for storage or parsing later.\n",
    "    \"\"\"\n",
    "\n",
    "    # Set up your Geocoding url\n",
    "    geocode_url = \"https://maps.googleapis.com/maps/api/geocode/json?latlng={}\".format(address)\n",
    "    if api_key is not None:\n",
    "        geocode_url = geocode_url + \"&key={}\".format(api_key)\n",
    "        \n",
    "    # Ping google for the reuslts:\n",
    "    results = requests.get(geocode_url)\n",
    "    # Results will be in JSON format - convert to dict using requests functionality\n",
    "    results = results.json()\n",
    "    \n",
    "    # if there's no results or an error, return empty results.\n",
    "    if len(results['results']) == 0:\n",
    "        output = {\n",
    "\n",
    "            \"postcode\": None\n",
    "        }\n",
    "    else:    \n",
    "        answer = results['results'][0]\n",
    "        output = {\n",
    "             #\"formatted_address\" : answer.get('formatted_address'),\n",
    "            #\"google_place_id\": answer.get(\"place_id\"),\n",
    "           # \"type\": \",\".join(answer.get('types')),\n",
    "            \"postcode\": \",\".join([x['long_name'] for x in answer.get('address_components') \n",
    "                                  if 'postal_code' in x.get('types')])\n",
    "        }\n",
    "        \n",
    "    # Append some other details:    \n",
    "    output['input_string'] = address\n",
    "    output['number_of_results'] = len(results['results'])\n",
    "    output['status'] = results.get('status')\n",
    "    if return_full_response is True:\n",
    "        output['response'] = results\n",
    "    \n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list to hold results\n",
    "results = []\n",
    "# Go through each address in turn\n",
    "for address in addresses:\n",
    "    # While the address geocoding is not finished:\n",
    "    geocoded = False\n",
    "    while geocoded is not True:\n",
    "        # Geocode the address with google\n",
    "        try:\n",
    "            geocode_result = get_google_results(address, API_KEY, return_full_response=RETURN_FULL_RESULTS)\n",
    "        except Exception as e:\n",
    "            logger.exception(e)\n",
    "            logger.error(\"Major error with {}\".format(address))\n",
    "            logger.error(\"Skipping!\")\n",
    "            geocoded = True\n",
    "            \n",
    "        # If we're over the API limit, backoff for a while and try again later.\n",
    "        if geocode_result['status'] == 'OVER_QUERY_LIMIT':\n",
    "            logger.info(\"Hit Query Limit! Backing off for a bit.\")\n",
    "            time.sleep(BACKOFF_TIME * 60) # sleep for 30 minutes\n",
    "            geocoded = False\n",
    "        else:\n",
    "            # If we're ok with API use, save the results\n",
    "            # Note that the results might be empty / non-ok - log this\n",
    "            if geocode_result['status'] != 'OK':\n",
    "                logger.warning(\"Error geocoding {}: {}\".format(address, geocode_result['status']))\n",
    "            logger.debug(\"Geocoded: {}: {}\".format(address, geocode_result['status']))\n",
    "            results.append(geocode_result)           \n",
    "            geocoded = True\n",
    "\n",
    "    # Print status every 100 addresses\n",
    "    if len(results) % 100 == 0:\n",
    "        logger.info(\"Completed {} of {} address\".format(len(results), len(addresses)))\n",
    "            \n",
    "    # Every 500 addresses, save progress to file(in case of a failure so you have something!)\n",
    "    if len(results) % 500 == 0:\n",
    "        pd.DataFrame(results).to_csv(\"{}_bak\".format(output_filename))\n",
    "\n",
    "# All done\n",
    "logger.info(\"Finished geocoding all addresses\")\n",
    "# Write the full results to csv using the pandas library.\n",
    "pd.DataFrame(results).to_csv(output_filename, encoding='utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new column with the results\n",
    "df['postalcode']= [x['postcode'] for x in results]\n",
    "#since the table is organized by location, we can fill the nulls by taking its neighbors postal code (forward fill)\n",
    "df=df.fillna(method='ffill', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('venues_barcelona_withdetails.csv', index=False , encoding='utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
